{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "boYPyI0MdVTn"
      },
      "source": [
        "# Pre Trained Image classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "colab_type": "code",
        "id": "pWkVRYJ_Pa-t",
        "outputId": "3c6f8fe6-eec9-4215-dee8-01484485f596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torchvision in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (0.16.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from torchvision) (10.1.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from torchvision) (2.1.0)\n",
            "Requirement already satisfied: requests in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: numpy in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from torchvision) (1.26.1)\n",
            "Requirement already satisfied: sympy in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: fsspec in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from torch==2.1.0->torchvision) (2023.9.2)\n",
            "Requirement already satisfied: jinja2 in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: networkx in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from torch==2.1.0->torchvision) (3.2)\n",
            "Requirement already satisfied: typing-extensions in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from torch==2.1.0->torchvision) (4.8.0)\n",
            "Requirement already satisfied: filelock in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from torch==2.1.0->torchvision) (3.12.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/vbustillos/Library/Python/3.9/lib/python/site-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3 is available.\n",
            "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Make sure torchvision-0.3.0 (latest version) is installed\n",
        "!pip3 install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0SlHsDqPPtMi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vbustillos/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Import torch and torchvision modules\n",
        "import torch\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1003
        },
        "colab_type": "code",
        "id": "-d7vH5B2P02M",
        "outputId": "d6306d22-c0d0-4136-f22c-1ec72a67aaab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['AlexNet',\n",
              " 'AlexNet_Weights',\n",
              " 'ConvNeXt',\n",
              " 'ConvNeXt_Base_Weights',\n",
              " 'ConvNeXt_Large_Weights',\n",
              " 'ConvNeXt_Small_Weights',\n",
              " 'ConvNeXt_Tiny_Weights',\n",
              " 'DenseNet',\n",
              " 'DenseNet121_Weights',\n",
              " 'DenseNet161_Weights',\n",
              " 'DenseNet169_Weights',\n",
              " 'DenseNet201_Weights',\n",
              " 'EfficientNet',\n",
              " 'EfficientNet_B0_Weights',\n",
              " 'EfficientNet_B1_Weights',\n",
              " 'EfficientNet_B2_Weights',\n",
              " 'EfficientNet_B3_Weights',\n",
              " 'EfficientNet_B4_Weights',\n",
              " 'EfficientNet_B5_Weights',\n",
              " 'EfficientNet_B6_Weights',\n",
              " 'EfficientNet_B7_Weights',\n",
              " 'EfficientNet_V2_L_Weights',\n",
              " 'EfficientNet_V2_M_Weights',\n",
              " 'EfficientNet_V2_S_Weights',\n",
              " 'GoogLeNet',\n",
              " 'GoogLeNetOutputs',\n",
              " 'GoogLeNet_Weights',\n",
              " 'Inception3',\n",
              " 'InceptionOutputs',\n",
              " 'Inception_V3_Weights',\n",
              " 'MNASNet',\n",
              " 'MNASNet0_5_Weights',\n",
              " 'MNASNet0_75_Weights',\n",
              " 'MNASNet1_0_Weights',\n",
              " 'MNASNet1_3_Weights',\n",
              " 'MaxVit',\n",
              " 'MaxVit_T_Weights',\n",
              " 'MobileNetV2',\n",
              " 'MobileNetV3',\n",
              " 'MobileNet_V2_Weights',\n",
              " 'MobileNet_V3_Large_Weights',\n",
              " 'MobileNet_V3_Small_Weights',\n",
              " 'RegNet',\n",
              " 'RegNet_X_16GF_Weights',\n",
              " 'RegNet_X_1_6GF_Weights',\n",
              " 'RegNet_X_32GF_Weights',\n",
              " 'RegNet_X_3_2GF_Weights',\n",
              " 'RegNet_X_400MF_Weights',\n",
              " 'RegNet_X_800MF_Weights',\n",
              " 'RegNet_X_8GF_Weights',\n",
              " 'RegNet_Y_128GF_Weights',\n",
              " 'RegNet_Y_16GF_Weights',\n",
              " 'RegNet_Y_1_6GF_Weights',\n",
              " 'RegNet_Y_32GF_Weights',\n",
              " 'RegNet_Y_3_2GF_Weights',\n",
              " 'RegNet_Y_400MF_Weights',\n",
              " 'RegNet_Y_800MF_Weights',\n",
              " 'RegNet_Y_8GF_Weights',\n",
              " 'ResNeXt101_32X8D_Weights',\n",
              " 'ResNeXt101_64X4D_Weights',\n",
              " 'ResNeXt50_32X4D_Weights',\n",
              " 'ResNet',\n",
              " 'ResNet101_Weights',\n",
              " 'ResNet152_Weights',\n",
              " 'ResNet18_Weights',\n",
              " 'ResNet34_Weights',\n",
              " 'ResNet50_Weights',\n",
              " 'ShuffleNetV2',\n",
              " 'ShuffleNet_V2_X0_5_Weights',\n",
              " 'ShuffleNet_V2_X1_0_Weights',\n",
              " 'ShuffleNet_V2_X1_5_Weights',\n",
              " 'ShuffleNet_V2_X2_0_Weights',\n",
              " 'SqueezeNet',\n",
              " 'SqueezeNet1_0_Weights',\n",
              " 'SqueezeNet1_1_Weights',\n",
              " 'SwinTransformer',\n",
              " 'Swin_B_Weights',\n",
              " 'Swin_S_Weights',\n",
              " 'Swin_T_Weights',\n",
              " 'Swin_V2_B_Weights',\n",
              " 'Swin_V2_S_Weights',\n",
              " 'Swin_V2_T_Weights',\n",
              " 'VGG',\n",
              " 'VGG11_BN_Weights',\n",
              " 'VGG11_Weights',\n",
              " 'VGG13_BN_Weights',\n",
              " 'VGG13_Weights',\n",
              " 'VGG16_BN_Weights',\n",
              " 'VGG16_Weights',\n",
              " 'VGG19_BN_Weights',\n",
              " 'VGG19_Weights',\n",
              " 'ViT_B_16_Weights',\n",
              " 'ViT_B_32_Weights',\n",
              " 'ViT_H_14_Weights',\n",
              " 'ViT_L_16_Weights',\n",
              " 'ViT_L_32_Weights',\n",
              " 'VisionTransformer',\n",
              " 'Weights',\n",
              " 'WeightsEnum',\n",
              " 'Wide_ResNet101_2_Weights',\n",
              " 'Wide_ResNet50_2_Weights',\n",
              " '_GoogLeNetOutputs',\n",
              " '_InceptionOutputs',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_api',\n",
              " '_meta',\n",
              " '_utils',\n",
              " 'alexnet',\n",
              " 'convnext',\n",
              " 'convnext_base',\n",
              " 'convnext_large',\n",
              " 'convnext_small',\n",
              " 'convnext_tiny',\n",
              " 'densenet',\n",
              " 'densenet121',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'detection',\n",
              " 'efficientnet',\n",
              " 'efficientnet_b0',\n",
              " 'efficientnet_b1',\n",
              " 'efficientnet_b2',\n",
              " 'efficientnet_b3',\n",
              " 'efficientnet_b4',\n",
              " 'efficientnet_b5',\n",
              " 'efficientnet_b6',\n",
              " 'efficientnet_b7',\n",
              " 'efficientnet_v2_l',\n",
              " 'efficientnet_v2_m',\n",
              " 'efficientnet_v2_s',\n",
              " 'get_model',\n",
              " 'get_model_builder',\n",
              " 'get_model_weights',\n",
              " 'get_weight',\n",
              " 'googlenet',\n",
              " 'inception',\n",
              " 'inception_v3',\n",
              " 'list_models',\n",
              " 'maxvit',\n",
              " 'maxvit_t',\n",
              " 'mnasnet',\n",
              " 'mnasnet0_5',\n",
              " 'mnasnet0_75',\n",
              " 'mnasnet1_0',\n",
              " 'mnasnet1_3',\n",
              " 'mobilenet',\n",
              " 'mobilenet_v2',\n",
              " 'mobilenet_v3_large',\n",
              " 'mobilenet_v3_small',\n",
              " 'mobilenetv2',\n",
              " 'mobilenetv3',\n",
              " 'optical_flow',\n",
              " 'quantization',\n",
              " 'regnet',\n",
              " 'regnet_x_16gf',\n",
              " 'regnet_x_1_6gf',\n",
              " 'regnet_x_32gf',\n",
              " 'regnet_x_3_2gf',\n",
              " 'regnet_x_400mf',\n",
              " 'regnet_x_800mf',\n",
              " 'regnet_x_8gf',\n",
              " 'regnet_y_128gf',\n",
              " 'regnet_y_16gf',\n",
              " 'regnet_y_1_6gf',\n",
              " 'regnet_y_32gf',\n",
              " 'regnet_y_3_2gf',\n",
              " 'regnet_y_400mf',\n",
              " 'regnet_y_800mf',\n",
              " 'regnet_y_8gf',\n",
              " 'resnet',\n",
              " 'resnet101',\n",
              " 'resnet152',\n",
              " 'resnet18',\n",
              " 'resnet34',\n",
              " 'resnet50',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext101_64x4d',\n",
              " 'resnext50_32x4d',\n",
              " 'segmentation',\n",
              " 'shufflenet_v2_x0_5',\n",
              " 'shufflenet_v2_x1_0',\n",
              " 'shufflenet_v2_x1_5',\n",
              " 'shufflenet_v2_x2_0',\n",
              " 'shufflenetv2',\n",
              " 'squeezenet',\n",
              " 'squeezenet1_0',\n",
              " 'squeezenet1_1',\n",
              " 'swin_b',\n",
              " 'swin_s',\n",
              " 'swin_t',\n",
              " 'swin_transformer',\n",
              " 'swin_v2_b',\n",
              " 'swin_v2_s',\n",
              " 'swin_v2_t',\n",
              " 'vgg',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn',\n",
              " 'video',\n",
              " 'vision_transformer',\n",
              " 'vit_b_16',\n",
              " 'vit_b_32',\n",
              " 'vit_h_14',\n",
              " 'vit_l_16',\n",
              " 'vit_l_32',\n",
              " 'wide_resnet101_2',\n",
              " 'wide_resnet50_2']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Print the models available in torchvision\n",
        "dir(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QL1bqOU_Qd-t"
      },
      "outputs": [],
      "source": [
        "# Specify image transformations\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([            #[1]\n",
        " transforms.Resize(256),                    #[2]\n",
        " transforms.CenterCrop(224),                #[3]\n",
        " transforms.ToTensor(),                     #[4]\n",
        " transforms.Normalize(                      #[5]\n",
        " mean=[0.485, 0.456, 0.406],                #[6]\n",
        " std=[0.229, 0.224, 0.225]                  #[7]\n",
        " )])\n",
        "\n",
        "# Line [1]: Here we are defining a variable transform which is a combination of all the image transformations to be carried out on the input image.\n",
        "\n",
        "# Line [2]: Resize the image to 256×256 pixels.\n",
        "\n",
        "# Line [3]: Crop the image to 224×224 pixels about the center.\n",
        "\n",
        "# Line [4]: Convert the image to PyTorch Tensor data type.\n",
        "\n",
        "# Line [5-7]: Normalize the image by setting its mean and standard deviation to the specified values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "9qtOK2ZLTwss",
        "outputId": "97457bf6-0d41-4dbf-9807-016c594fc998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-19 17:53:30--  https://upload.wikimedia.org/wikipedia/commons/2/26/YellowLabradorLooking_new.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83281 (81K) [image/jpeg]\n",
            "Saving to: ‘dog.jpg’\n",
            "\n",
            "dog.jpg             100%[===================>]  81.33K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-10-19 17:53:33 (1.11 MB/s) - ‘dog.jpg’ saved [83281/83281]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download image\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/2/26/YellowLabradorLooking_new.jpg -O dog.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "G31tXCQxa1AZ",
        "outputId": "edd82d25-72ed-4c0a-afb2-d48e610adeed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-19 17:53:49--  https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21674 (21K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt’\n",
            "\n",
            "imagenet_classes.tx 100%[===================>]  21.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-19 17:53:49 (103 MB/s) - ‘imagenet_classes.txt’ saved [21674/21674]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download classes text file\n",
        "!wget https://raw.githubusercontent.com/Lasagne/Recipes/master/examples/resnet50/imagenet_classes.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jex0-5RuaNRP"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.open(\"dog.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cbPGrVeRapB9"
      },
      "outputs": [],
      "source": [
        "img_t = transform(img)\n",
        "batch_t = torch.unsqueeze(img_t, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "_HoQbsp8coVb",
        "outputId": "d41d63e4-b47c-49e3-9aee-92b084093561"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vbustillos/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/vbustillos/Library/Python/3.9/lib/python/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Load alexnet model\n",
        "alexnet = models.alexnet(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "colab_type": "code",
        "id": "FetOTbiTc72w",
        "outputId": "e5bfa8bf-a555-42e0-fbf0-0d82cfcfcf02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(alexnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "colab_type": "code",
        "id": "pBc7fC2Hc-Xm",
        "outputId": "79aa6483-dd26-455f-db37-0c44cc34b6e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Put our model in eval mode\n",
        "alexnet.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "BtZvoeNkdCkI",
        "outputId": "582ef133-c73a-4702-faa4-b5c144085713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1000])\n"
          ]
        }
      ],
      "source": [
        "# Carry out inference\n",
        "out = alexnet(batch_t)\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Y5pqY-qXdDgv"
      },
      "outputs": [],
      "source": [
        "# Load labels\n",
        "with open('imagenet_classes.txt') as f:\n",
        "  classes = [line.strip() for line in f.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "colab_type": "code",
        "id": "OATsity0dGoV",
        "outputId": "1e9cf967-f8d7-4468-ddb8-778042e1b7be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Labrador retriever', 42.46731185913086),\n",
              " ('golden retriever', 16.60867691040039),\n",
              " ('Saluki, gazelle hound', 15.473800659179688),\n",
              " ('whippet', 2.7881979942321777),\n",
              " ('Ibizan hound, Ibizan Podenco', 2.3617069721221924)]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_, indices = torch.sort(out, descending=True)\n",
        "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "[(classes[idx], percentage[idx].item()) for idx in indices[0][:5]]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Image-Classification-using-pre-trained-models.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
